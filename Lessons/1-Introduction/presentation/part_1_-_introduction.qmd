---
title: "Part 1 - Introduction to Machine Learning"
author: "Alexandre Bry"
incremental: true
slide-level: 3
reference-location: document
include-after-body: include-after-body.html
format:
  revealjs:
    transition: slide
    # theme: [default, _extensions/grantmcdermott/clean/clean.scss]
    theme: simple
    slide-number: true
    show-slide-number: all
    css: [styles.css]
    code-overflow: wrap
    code-line-numbers: false
    scrollable: true
execute: 
  echo: true
---

# Introduction

### Definition

::: {.definition-block}
Machine Learning (ML)

Feeding **data** into a computer **algorithm** in order to learn **patterns** and make **predictions** in new and different **situations**.
:::

### Dataset



# Categories of ML

### Available data

- Supervised: for each input in the dataset, the expected output is also part of the dataset
- Unsupervised: for each input in the dataset, the expected output is **not** part of the dataset
- Semi-supervised: only a portion of the inputs of the dataset have their expected output in the dataset
- Reinforcement: there is no predefined dataset, but an environment giving feedback to the model when it takes actions

### Output

- Classification: assigning one (or multiple) label(s) chosen from a given list of classes to each element of the input
- Regression: assigning one (or multiple) value(s) chosen from a continuous set of values
- Clustering: create categories by grouping together similar inputs

# Usual pipeline

- Data acquisition
- Data preprocessing
  - Outliers
  - Missing data
  - Formatting
  - Normalization
- Model selection
  - Type of model
  - Complexity
  - Parameters
- Model evaluation
  - Cross-validation
  - Hyperparameter tuning
- Final model training

# Overview of ML methods

- Linear Regression
- Decision Tree
- Random Forest
- Bagging?
- Maximum Likelihood Estimation

### Linear regression {auto-animate="true" auto-animate-easing="ease-in-out"}

::: {data-id="equation"}
$y = \beta_0 + \beta_1 X$
:::
 <!-- .fragment .fade-out -->

### Linear regression {auto-animate="true" auto-animate-easing="ease-in-out"}

<!-- $y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_n X_n$ {.fragment .fade-in} -->
::: {data-id="equation"}
$y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_n X_n$
:::


# Overview of NN methods

### Playground {.no-scrollable}

[Playground](https://playground.tensorflow.org/)

# Challenges

## Data

- Quality
- Diversity
- Biases and fairness (example of crime prediction)

## Underfitting and Overfitting

- Cross-validation
- Feature selection
- Regularization
- Ensemble methods
- Model complexity (increase if high bias and reduce if high variance)
- Early stopping (overfitting)
- Training data size (underfitting)

## Interpretable and Explainable

## Bias and variance (stability)

### Definitions

::: {.definition-block}
Interpretable

Qualifies a ML model which decision-making process is straightforward and **transparent**, making it directly **understandable** by humans. This requires to restrict the model **complexity**.
:::

::: {.definition-block}
Explainable

Qualifies a ML model which decision-making process can be partly interpreted afterwards using **post hoc interpretation techniques**. 
:::

### Examples

- Example of the model detecting fishes using human hands
- Depends a lot on the technique that is used

# Python libraries

## Data manipulation

### Libraries

::: {.fragment .nonincremental}
- [NumPy](https://numpy.org/)
  - Fast numerical operations
  - Matrices with any number of dimensions (called arrays)
  - Lots of convenient operators on arrays
:::
::: {.fragment .nonincremental}
- [Pandas](https://pandas.pydata.org/)
  - Can store any type of data
  - 1D or 2D tables (called DataFrames)
  - Lots of convenient operators on DataFrames
:::

### NumPy

::: {.fragment}
```{python}
import numpy as np
```
:::
::: {.fragment}
```{python}
array = np.array([[0, 1], [2, 3]])
print(array)
```
:::
::: {.fragment}
```{python}
print(5 * array)
```
:::
::: {.fragment}
```{python}
print(np.pow(array, 3))
```
:::
::: {.fragment}
```{python}
print(array @ array)
```
:::
::: {.fragment}
```{python}
print(np.where(array < 2, 10 - array, array))
```
:::

### Pandas

::: {.fragment}
```{python}
import pandas as pd
import numpy.random as npr
```
:::

::: {.fragment}
```{python}
df = pd.DataFrame([
    ["Pi", 3.14159, npr.randint(-100, 101, (2, 2))],
    ["Euler's number", 2.71828, npr.randint(-100, 101, (2, 2))],
    ["Golden ratio", 1.61803, npr.randint(-100, 101, (2, 2))]
  ], columns = ["Names", "Values", "Random numbers because why not"])
print(df)
```
:::

::: {.fragment}
```{python}
print(df[df["Values"] > 2])
```
:::

::: {.fragment}
```{python}
print(df[df["Names"].str.contains("n")])
```
:::

## ML

- [SciPy](https://scipy.org/)
- [scikit-learn](https://scikit-learn.org/stable/index.html)

## NN

- [PyTorch](https://pytorch.org/)
- [TensorFlow](https://www.tensorflow.org/)
- [Keras](https://keras.io/)

## Visualization

- [Matplotlib](https://matplotlib.org/)
- [Plotly](https://plotly.com/python/)
- [Seaborn](https://seaborn.pydata.org/index.html)

# Resources

## Machine Learning

- GeeksforGeeks:
  - [GeeksforGeeks Introduction to Machine Learning](https://www.geeksforgeeks.org/introduction-machine-learning/)
  - [GeeksforGeeks 7 Major ML Challenges](https://www.geeksforgeeks.org/7-major-challenges-faced-by-machine-learning-professionals/)
  - [GeeksforGeeks Explainable and Interpretable](https://www.geeksforgeeks.org/what-is-the-difference-between-explainable-and-interpretable-machine-learning/)
- [Interpretable Machine Learning, Christoph Molnar](https://christophm.github.io/interpretable-ml-book/)
